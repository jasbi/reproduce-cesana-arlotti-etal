---
title: "Eyetracking Cluster Analysis Vignette"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

## Preamble

This is a re-implementation of the eyetrackingR vignette on estimating divergences. The goal is to understand what eyetrackingR is doing "under the hood" so we can reimplement with our own code.

```{r}
knitr::opts_chunk$set(warning=F, cache=T, message=F)
```

```{r}
library(magrittr)
library(eyetrackingR)
library(tidyverse)
```

## Load data and convert to eyetrackingR format

```{r}
data("word_recognition")
data <- make_eyetrackingr_data(word_recognition, 
                       participant_column = "ParticipantName",
                       trial_column = "Trial",
                       time_column = "TimeFromTrialOnset",
                       trackloss_column = "TrackLoss",
                       aoi_columns = c('Animate','Inanimate'),
                       treat_non_aoi_looks_as_missing = TRUE
                )

# subset to response window post word-onset
response_window <- subset_by_window(data, 
                                    window_start_time = 15500, 
                                    window_end_time = 21000, 
                                    rezero = FALSE)
```

### Set response window and filter trials

```{r}
# analyze amount of trackloss by subjects and trials
(trackloss <- trackloss_analysis(data = response_window))

# remove trials with > 25% of trackloss
response_window_clean <- clean_by_trackloss(data = response_window,
                                            trial_prop_thresh = .25)

# create Target condition column
response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial), 
                                       yes = 'Inanimate', 
                                       no  = 'Animate') )
```

### Summarise proportion looking within each time bin

```{r}
response_time <- make_time_sequence_data(response_window_clean,
                                  time_bin_size = 100, 
                                  predictor_columns = c("Target"),
                                  aois = "Animate",
                                  summarize_by = "ParticipantName" )

# visualize timecourse
plot(response_time, predictor_column = "Target") + 
  theme_light() +
  coord_cartesian(ylim = c(0,1))
```

## Bootstrapped cluster-based permutation analysis

### Overview

This procedure involves two main steps. First, we run a test on each time bin that quantifies the statistical significance of the effect at each time bin. This acts as a “first pass,” and we group together into clusters all adjacent bins that get through this first pass. We then shuffle the data, performing this test-then-cluster on each iteration of the shuffled data. This shuffled data tells us what kinds of clusters we should expect if there were no effect (i.e., randomly scrambled data).

### In more detail, what eyetrackingR does is:

1. Run a statistical test on each time-bin of your data. This can be any valid and appropriate statistic test that quantifies the probability of the effect: t-test, wilcox.test, linear models, etc.– whatever is appropriate for your data.
2. Take the time-bins whose test passed the threshold statistic (e.g., t > 2), and group them by adjacency. We will call these time-clusters.
3. For each time-cluster, calculate the sum of the statistics for the time-bins inside it.
4. Take the data and randomly shuffle it.
5. Perform (1)-(3) on the shuffled dataset. Save the biggest sum-statistic.
6. Repeat steps (4) and (5) hundreds of times. This will lead to a distribution of summed-statistics, each representing the results of a statistical test on shuffled data. Intuitively, this distribution represents what kind of sum-statistics we would expect to get by chance, if no effect were present (i.e., if the data were just randomly shuffled).
7. Compare the cluster-statistics from step (3) to the distribution found in (6) to obtain a p-value. So, for example, if we get a distribution of sum-statistics, and 6.4% of the sum-statistics in this distribution are more extreme the sum-statistic of our cluster, then our p-value for this cluster is p = .064.

### Implemenation

First, we set our threshold for the first pass: 

```{r}
num_sub = length(unique((response_window_clean$ParticipantName)))
threshold_t = qt(p = 1 - .05/2, df = num_sub-1) # pick threshold t based on alpha = .05 two tailed
View(response_time)
```

Look for initial clusters

```{r}
df_timeclust <- make_time_cluster_data(response_time, 
                                      test= "t.test", paired=TRUE,
                                      predictor_column = "Target", 
                                      threshold = threshold_t) 

plot(df_timeclust) +  ylab("T-Statistic") + theme_light()
```

```{r}
summary(df_timeclust)
```

bootstraps a “null” distribution, which can be visualized:

```{r}
clust_analysis <- analyze_time_clusters(df_timeclust, 
                                        within_subj=TRUE,
                                        paired=TRUE,
                                        samples=1000) 
```

```{r}
plot(clust_analysis) + theme_light()
```



