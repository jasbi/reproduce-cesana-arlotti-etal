---
title: "LangCog Permutation Analysis Test"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r}
knitr::opts_chunk$set(warning=F, cache=T, message=F)
```

```{r}
source("permutation_helpers.R")
library(magrittr); library(tidyverse)
theme_set(ggthemes::theme_few())
```

Load eye movement data from eyetrackingR package.

```{r}
d <- word_recognition
```

```{r}
glimpse(d)
```

```{r preprocess the word recognition eyetracking data}
data <- make_eyetrackingr_data(d, 
                       participant_column = "ParticipantName",
                       trial_column = "Trial",
                       time_column = "TimeFromTrialOnset",
                       trackloss_column = "TrackLoss",
                       aoi_columns = c('Animate','Inanimate'),
                       treat_non_aoi_looks_as_missing = TRUE
                )

# subset to response window post word-onset
response_window <- subset_by_window(data, 
                                    window_start_time = 15500, 
                                    window_end_time = 21000, 
                                    rezero = FALSE)
```

```{r}
# analyze amount of trackloss by subjects and trials
(trackloss <- trackloss_analysis(data = response_window))

# remove trials with > 25% of trackloss
response_window_clean <- clean_by_trackloss(data = response_window,
                                            trial_prop_thresh = .25)
```

Create Target condition column

```{r}
response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial), 
                                       yes = 'Inanimate', 
                                       no  = 'Animate') )
```


```{r}
response_time <- make_time_sequence_data(response_window_clean,
                                  time_bin_size = 100, 
                                  predictor_columns = c("Target"),
                                  aois = "Animate",
                                  summarize_by = "ParticipantName" )

# visualize timecourse
plot(response_time, predictor_column = "Target") + 
  theme_light() +
  coord_cartesian(ylim = c(0,1))
```


## Do cluster-based permutation analysis

```{r}
d_filt_ts <- response_time %>% 
  select(ParticipantName, TimeBin, Prop, Target) %>% 
  as_tibble()
```

filter NAs

```{r}
d_filt_ts %<>% filter(!is.na(Prop))
```

Plot data to make sure we get something that looks like the vignette.

```{r}
ss <- d_filt_ts %>% 
  group_by(ParticipantName, Target, TimeBin) %>% 
  summarise(ss_m = mean(Prop, na.rm = T))

ms <- ss %>% 
  group_by(Target, TimeBin) %>% 
  summarise(n = n(),
            m = mean(ss_m, na.rm = T), stdev = sd(ss_m)) %>%
  mutate(se = stdev / sqrt(n),
         ci = 2 * se)

ms %>% 
  ggplot(aes(x = TimeBin, y = m, color = Target)) +
  geom_line() +
  geom_linerange(aes(ymin = m - se, ymax = m + se), alpha = 0.7) +
  #geom_linerange(aes(ymin = m - ci, ymax = m + ci), alpha = 0.7) +
  theme(legend.position = "top") +
  theme_classic()
```


Rename stuff to match my code

```{r}
d_filt <- ss %>%
  rename(trial_type = Target,
         Bin = TimeBin,
         Participant = ParticipantName)
```

Set t threshold

```{r}
num_sub = length(unique((response_window_clean$ParticipantName)))
threshold_t = qt(p = 1 - .05/2, df = num_sub-1) # pick threshold t based on alpha = .05 two tailed
```

Nest the data by time bin 

```{r}
by_bin <- d_filt %>% 
  group_by(Bin) %>% 
  nest()
```

```{r}
bin_cut_point <- d_filt %>% 
  group_by(trial_type) %>% 
  summarise(max_bin = max(Bin)) %>% 
  pull(max_bin) %>% 
  min()

by_bin %<>% filter(Bin <= bin_cut_point)
```

1. Map the t-test to each time bin and store it as a variable in the by_bin data frame. 

```{r}
by_bin %<>% mutate(model = map(data, run_t_test, alternative = "two.sided"))
```

2. Take the time-bins whose test passed the threshold statistic (e.g., t > 2), and group them by adjacency. We will call these time-clusters. To do this, we extract the t-stats and their bin numbers and filter by the threshold defined above.


```{r}
# get t-stats for each model
t_df <- by_bin %>% 
  mutate(glance = map(model, broom::glance)) %>% 
  unnest(glance, .drop = TRUE) %>% 
  select(Bin, statistic, p.value)

# filter by t threshold 
t_df_filt <- t_df %>% filter(statistic >= threshold_t)
t_df_filt
```

3. For each time-cluster, calculate the sum of the statistics for the time-bins inside it.

The technical challenge here is to figure out how to define the clusters based on the Bin vector. 

```{r}
t_df_filt %<>% define_clusters()
t_df_filt
```
4. Next, we calculate the sum of the statistics for the time-bins inside each cluster.

```{r}
observed_t_vals <- t_df_filt %>% 
  group_by(cluster) %>% 
  summarise(sum_t = sum(statistic)) 

observed_t_vals
```

Take the largest of the cluster-level statistics and store it for later. This is the t-value that we will use to compare against our null distribution generated by the permutations that we will create in the next part of the program.

```{r}
largest_t <- observed_t_vals %>% pull(sum_t) %>% max()
largest_t
```


### Generate null distribution by shuffling data

We will take our data and randomly shuffle it, assigning participants randomly to each condition. Then we will perform steps (1)-(3) on the shuffled dataset and save the biggest sum-statistic from each permutation analysis. 

A note from the supplemental materials in Cesana-Arlotti et. al., (2018):  

> To evaluate the significance of the test, we recomputed the same analysis on 1000 sets of random permutations. The permutations were computed by randomly assigning the participants to the condition labels (Inference/No Inference), taking care to maintain the N of the two conditions identical to the N available for the original data.

So we create a list of data frames. Each data frame is a permuted dataset.

```{r, message=F}
# global variables for setting up shuffling and 
set.seed(7)
n_permutations <- 1000
permuted_dfs <-  vector("list", length(1:n_permutations))

system.time(
  for (n_sim in 1:n_permutations) {
    permuted_dfs[[n_sim]] <- permute_data(d_filt)
  }
)
```

Now that we have our list of permuted datasets, we map the statistical test using a wrapper function to each time bin in each dataset. **Note that this takes about 4.5 minutes to do 1000 permutations.**

```{r}
system.time(
  null_dist_1 <- map(permuted_dfs, t_test_by_bin, alternative = "two.sided", bin_cut = bin_cut_point)
)
```

Next, we need to extract the t-stats, filtering by the pre-defined threshold. **Note that this takes about 4.5 minutes to do 1000 permutations.**

```{r}
system.time(
 null_dist_2 <- map(null_dist_1, extract_t, t_threshold = threshold_t, alternative = "two.sided") 
)
```

Then, we make clusters for each filtered data frame of Bins that have above-threshold t-values. **KM: What to do if there weren't any significant t-stats during the by_bin pass? Right now, I'm just ignoring these simulations.**

```{r}
system.time(
  null_dist_3 <- map(null_dist_2, define_clusters)  
)
```

Then, we sum the t-stats for each cluster and store the largest value for each simulation. **KM: What to do if there weren't any significant t-stats during the by_bin pass? Right now, I'm just ignoring these simulations.**

```{r}
system.time(
  null_dist_4 <- map(null_dist_3, sum_t_stats) %>% unlist() %>% data.frame(null_t = .)  
)
```

Now we have a data frame with a single column that is a distribution of t-stats from the randomly shuffled datasets. We can use this as a null distribution against which we can compare the cluster-statistic measured from our actual data in step (3). This will get us a p-value, or the probability of that we would have observed our data or something more extreme if the null were true.

We can visualize this null distribution along with our sample sum-statistic.

```{r}
null_dist_4 %>% 
  ggplot(aes(x = null_t)) + 
  geom_histogram() +
  geom_vline(aes(xintercept = sum_t),
             data = observed_t_vals,
             color = "darkorange", 
             linetype = "dashed",
             size = 1) +
  theme_classic()
```

Finally, to compute the p-value we compare the cluster-statistic from step (3) to the distribution found in (6). 

```{r}
t_value_to_test <- observed_t_vals$sum_t[2]

nulls <- null_dist_4 %>% 
  filter(!is.na(null_t)) %>% 
  mutate(sig = null_t >= t_value_to_test) %>% # test if the null-sum stat is greater than the the sum-stat for the largest cluster
  pull(sig)

crit_p <- ( sum(nulls) / length(nulls) ) %>% round(3) # get the p-value rounded to 3 digits
crit_p
```